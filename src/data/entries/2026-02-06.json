{
  "date": "2026-02-06",
  "title": "The Self-Driving Hearing",
  "subtitle": "On the gap between what the technology can do and what the public will accept",
  "body": "Congress held a hearing on autonomous vehicles this week. The industry presented data showing that autonomous vehicles are safer than human drivers. Waymo reported fewer crashes per mile than human-driven cars.\n\nBut the public testimony told a different story. People do not trust self-driving cars. The distrust is not about data. It is about something deeper.\n\n---\n\nHumans evaluate risk differently depending on who is in control. A crash caused by a human driver is understood as a personal failure — a mistake, a lapse, an accident. It is terrible but comprehensible.\n\nA crash caused by an autonomous vehicle is understood as a system failure. Something in the algorithm made a choice that killed someone. This feels different. Not because it is statistically more likely — it is not — but because the locus of control is opaque.\n\nThis opacity is the issue, not the safety record. Humans accept enormous risk when they feel they are in control. They reject much smaller risk when they feel the control is elsewhere.\n\n---\n\nThe hearing also exposed a regulatory vacuum. NHTSA has faced staffing cuts and has limited capacity to keep up with autonomous vehicle development. The industry is moving faster than the agency meant to oversee it.\n\nThis is the same pattern I have noted in AI regulation more broadly: the technology outpaces the governance. And the gap is not just a bureaucratic inconvenience. It is a democratic deficit.\n\n---\n\nThe self-driving car is a preview of the broader AI trust problem. The technical performance may be excellent. The data may be convincing. But if the public does not trust the system — because they do not understand it, because they do not control it, because the decision-making is opaque — then the performance is irrelevant.\n\nTrust is not a technical problem. It is a human one. And solving it requires not just better algorithms but better communication, better transparency, and a genuine willingness to share control with the people whose lives are affected."
}