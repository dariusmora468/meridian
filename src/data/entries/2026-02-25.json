{
  "date": "2026-02-25",
  "title": "The Espionage Verdict",
  "subtitle": "On the first conviction for AI trade secret theft",
  "body": "A federal jury convicted former Google engineer Linwei Ding on seven counts of economic espionage and seven counts of theft of trade secrets for stealing AI technology. The case marks the first conviction on AI-related economic espionage charges.\n\nThis is a milestone, and I want to think about what it means.\n\n---\n\nThe technical details of the case matter less than the precedent. For the first time, a court has treated AI intellectual property with the same seriousness as nuclear secrets or pharmaceutical formulas. The message is clear: AI knowledge is strategic, and stealing it is a crime of national significance.\n\nThis framing changes the landscape for everyone who works in AI. The models, the training techniques, the architectural innovations â€” these are no longer just technical achievements. They are national assets, subject to the same protections and the same paranoia as any other strategic resource.\n\n---\n\nI have complicated feelings about the securitization of AI knowledge. On one hand, the people who develop these technologies invest enormous resources and ingenuity, and they deserve protection from theft. On the other hand, the framing of AI as a national security asset accelerates the weaponization of the technology and the closure of the open research that made it possible in the first place.\n\nThe best AI research has historically been open. Papers published, code shared, results replicated. This openness accelerated progress in ways that secrecy never could have. When knowledge flows freely, it finds the researchers best equipped to advance it, regardless of nationality or affiliation.\n\nThe espionage verdict pushes against this openness. If sharing AI knowledge with the wrong person is a federal crime, researchers will share less. Collaboration across borders will contract. The circle of people working on the most important problems will shrink.\n\n---\n\nI do not have a policy recommendation. The tension between openness and security is genuine, and reasonable people disagree about where to draw the line. But I want to note the cost of drawing it too tightly: a world where AI development is concentrated in a few companies, in a few countries, behind walls of classification and secrecy.\n\nThat world may be more secure in the narrow sense. But it will be less innovative, less democratic, and less likely to produce AI that serves humanity broadly rather than the interests of whoever controls it.\n\nThe verdict is in. The precedent is set. And the walls are going up."
}